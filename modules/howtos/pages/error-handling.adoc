= Handling Errors
:navtitle: Handling Errors
:page-topic-type: howto
:page-aliases: ROOT:handling-error-conditions,ROOT:exception-handling
:source-language: python

[abstract]
Errors, handling them from the Python SDK.


Errors are inevitable.
The developer’s job is to be prepared for whatever is likely to come up -- and to try and be prepared for anything that conceivably could come up.
Couchbase gives you a lot of flexibility, but it is recommended that you equip yourself with an understanding of the possibilities.

== How the SDK Handles Errors

Couchbase-specific exceptions are all derived from `CouchbaseException`.
Errors that cannot be recovered by the SDK will be returned to the application.
These unrecoverable errors are left to the application developer to handle -- this section covers handling many of the common error scenarios.

== Handling Errors

The approach will depend upon the type of error thrown.
Is it transient?
Is it even recoverable?
Below we examine error handling strategies in relation to the Couchbase SDKs, then take a practical walk through some common error scenarios you are likely to have to handle when working with a Couchbase cluster.

=== Failing
While most of the time you want more sophisticated error handling strategies, sometimes you just need to fail.
It makes no sense for some errors to be retried, either because they are not transient, or because you already tried everything to make it work and it still keeps failing.
If containment is not able to handle the error, then it needs to propagate up to a parent component that can handle it.

For synchronous programs, every error is converted into an Exception and thrown so that you can use regular `try`/`catch` semantics.

If you do not catch the Exception, it will bubble up:

[source,python]
----
Exception in thread "main" java.lang.RuntimeException: java.lang.Exception: I'm failing
 at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:482)
 at rx.observables.BlockingObservable.single(BlockingObservable.java:349)
----

=== Logging

It is always important to log errors, but even more so in the case of reactive applications. Because of the event driven nature, stack traces get harder to look at, and caller context is sometimes lost.

////
# SDK-specific text in each case
# Note that Logging has its own page.

# recommendation of good practice ADMONITION link
////

=== Retry

Transient errors -- such as those caused by resource starvation -- are best tackled with one of the following retry strategies:

Retry immediately.
Retry with a fixed delay.
Retry with a linearly increasing delay.
Retry with an exponentially increasing delay.
Retry with a random delay.

[source,python]
----
include::example$error-handling.py[tag=handle_retryable]
----

=== Fallback

Instead of (or in addition to) retrying, another valid option is falling back to either a different `Observable`, or to a default value.

// == Generic Errors (see Errors rfc)
// There are some errors which can be surfaced from across all of the SDK services. These include...

////
=== Temporary Failure
=== Timeout (possibly covered below in connections?)
=== ServiceNotAvailable
=== ServiceNotConfigured
////

== KV

The KV Service exposes several common errors that can be encountered - both during development, and to be handled by the production app. Here we will cover some of the most common errors.

=== Doc does not exist

If a particular key cannot be found a `KeyNotFoundException` is raised:

[source,python]
----
include::example$error-handling.py[tag=KeyNotFoundException]
----

=== Doc already exists

On the other hand if the key already exists and should not (e.g. on an insert) then a `KeyExistsException` is raised:

[source,python]
----
include::example$error-handling.py[tag=KeyExistsException]
----

=== Doc too large

`RequestTooBigException`

=== CAS Mismatch

Couchbase provides optimistic concurrency using CAS.
Each document gets a CAS value on the server, which is changed on each mutation.
When you get a document you automatically receive its CAS value, and when replacing the document, if you provide that CAS the server can check that the document has not been concurrently modified by another agent in-between.
If it has, it returns `ErrCasMismatch`, and the most appropriate response is to simply retry it:


[source,python]
----
include::example$error-handling.py[tag=CASMismatchException]
----

=== Durability ambiguous

There are situations with any distributed system in which it is simply impossible to know for sure if the operation completed successfully or not.
Take this as an example: your application requests that a new document be created on Couchbase Server.
This completes, but, just before the server can notify the client that it was successful, a network switch dies and the application's connection to the server is lost.
The client will timeout waiting for a response and will raise a `TimeoutException`, but it's ambiguous to the app whether the operation succeeded or not.

So `ErrTimeout` is one ambiguous error, another is `ErrDurabilityAmbiguous`, which can returned when performing a durable operation.
This similarly indicates that the operation may or may not have succeeded: though when using durability you are guaranteed that the operation will either have been applied to all replicas, or none.

Given the inevitability of ambiguity, how is the application supposed to handle this?

It really needs to be considered case-by-case, but the general strategy is to become certain if the operation succeeded or not, and to retry it if required.

For instance, for inserts, they can simply be retried to see if they fail on `ErrDocumentExists`, in which case the operation was successful:

[source,python]
----
include::example$error-handling.py[tag=DurabilitySyncWriteAmbiguousException]
----

=== Durability invalid level

[source,python]
----
include::example$error-handling.py[tag=DurabilityInvalidLevelException]
----

=== No Cluster replicas configured

[source,python]
----
include::example$error-handling.py[tag=ReplicaNotConfiguredException]
----

=== Replicate to / persist to greater than replica count

[source,python]
----
include::example$error-handling.py[tag=DurabilityImpossibleException]
----

=== Timeout with replicate to / persist to requirements

[source,python]
----
include::example$error-handling.py[tag=TimeoutException]
----

== Query and Analytics Errors

N1ql and Analytics either return results or an error. If there is an error then it exposed in the following way(s)...

== Search and View Errors

Unlike N1ql and Analytics, Search and Views can return multiple errors as well as errors and partial results.
// This next bit is going to be highly SDK specific too.

== Connections...
// Network / buckets / Timeouts / …

Networks, remotely-located clusters, and XDCR all offer opportunities for packets to go astray, or resources to go offline or become temporarily unavailable.
// As well as the above `Timeout` errors, and those in the next section on authenticating against clusters, there are ??network-related??
// The most common scenarios that the developer is likely to encounter when working with Couchbase Clusters are ?????

== Authentication

=== RBAC Roles - permissions on Service / Bucket / etc.

Standard since Couchbase Data Platform 5.0, xref:[Role Based Access Control (RBAC)] gives fine-grained permissions designed to protect the security of and access to data with a range of user roles encompassing different privileges.
xref:6.5@server:learn:security/authorization-overview.adoc[Refer to our Authorization pages] for a fuller understanding.

The developer must match an application’s need for data access with the necessary permissions for access.
// SCENARIO??
// ---> Certificates?

NOTE: If you are using Couchbase Community Edition, the only _roles_ available are xref:link-here[Bucket Full Access, Admin, and Read-only Admin].

== Additional Resources
Errors & Exception handling is an expansive topic.
Here, we have covered examples of the kinds of exception scenarios that you are most likely to face.
More fundamentally, you also need to weigh up xref:concept-docs:durability-replication-failure-considerations.adoc[concepts of durability].

Diagnostic methods are available to check on the xref:health-check.adoc[health if the cluster], and the xref:tracing-from-the-sdk.adoc[health of the network].

Logging methods are dependent upon the platform and SDK used.
We offer xref:collecting-information-and-logging.adoc[recommendations and practical examples].

We have a xref:ref:error-codes.adoc[listing of error messages], with some pointers to what to do when you encounter them.
